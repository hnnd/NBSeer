"""
Main entry point for NBSeer - Plant NBS gene annotation tool

Provides command-line interface and main execution logic
"""

import argparse
import sys
import time
from pathlib import Path

from .data.validation import DataValidator
from .pipeline.coordinator import NBSAnnotationPipeline
from .utils.config import load_config, load_config_with_overrides
from .utils.exceptions import NBSAnnotationError
from .utils.logging_setup import get_logger, setup_logging


def setup_argument_parser() -> argparse.ArgumentParser:
    """
    Set up command line argument parser
    è®¾ç½®å‘½ä»¤è¡Œå‚æ•°è§£æå™¨
    
    Returns:
        Configured ArgumentParser
    """
    parser = argparse.ArgumentParser(
        description="NBS Gene Annotation Pipeline - æ¤ç‰©NBSæŠ—ç—…åŸºå› é‡æ–°æ³¨é‡Šæµæ°´çº¿",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples / ç¤ºä¾‹:
  # Run full pipeline / è¿è¡Œå®Œæ•´æµæ°´çº¿
  %(prog)s --genome genome.fa --proteins proteins.fa --output results/

  # Run with custom configuration / ä½¿ç”¨è‡ªå®šä¹‰é…ç½®è¿è¡Œ
  %(prog)s --genome genome.fa --proteins proteins.fa --config custom.yaml

  # Run specific stage only / ä»…è¿è¡Œç‰¹å®šé˜¶æ®µ
  %(prog)s --genome genome.fa --stage nlr_localization

  # Validate input files only / ä»…éªŒè¯è¾“å…¥æ–‡ä»¶
  %(prog)s --genome genome.fa --proteins proteins.fa --validate-only

  # Check tool availability / æ£€æŸ¥å·¥å…·å¯ç”¨æ€§
  %(prog)s --check-tools
        """,
    )

    # Input files / è¾“å…¥æ–‡ä»¶
    input_group = parser.add_argument_group("Input Files", "è¾“å…¥æ–‡ä»¶")
    input_group.add_argument(
        "--genome", "-g",
        type=Path,
        help="Path to genome FASTA file / åŸºå› ç»„FASTAæ–‡ä»¶è·¯å¾„",
    )
    input_group.add_argument(
        "--proteins", "-p",
        type=Path,
        help="Path to protein FASTA file / è›‹ç™½è´¨FASTAæ–‡ä»¶è·¯å¾„",
    )
    input_group.add_argument(
        "--nlr-candidates",
        type=Path,
        help="Path to pre-computed NLR candidates file / é¢„è®¡ç®—çš„NLRå€™é€‰åŸºå› æ–‡ä»¶è·¯å¾„",
    )

    # Output options / è¾“å‡ºé€‰é¡¹
    output_group = parser.add_argument_group("Output Options", "è¾“å‡ºé€‰é¡¹")
    output_group.add_argument(
        "--output", "-o",
        type=Path,
        default=Path("output"),
        help="Output directory / è¾“å‡ºç›®å½• (default: output)",
    )
    output_group.add_argument(
        "--pipeline-id",
        type=str,
        help="Unique pipeline identifier / å”¯ä¸€æµæ°´çº¿æ ‡è¯†ç¬¦",
    )
    output_group.add_argument(
        "--format",
        choices=["gff", "gtf", "json", "all"],
        default="gff",
        help="Output format / è¾“å‡ºæ ¼å¼ (default: gff)",
    )

    # Configuration / é…ç½®
    config_group = parser.add_argument_group("Configuration", "é…ç½®")
    config_group.add_argument(
        "--config", "-c",
        type=Path,
        help="Path to configuration file / é…ç½®æ–‡ä»¶è·¯å¾„",
    )
    config_group.add_argument(
        "--override-config",
        type=Path,
        help="Path to override configuration file / è¦†ç›–é…ç½®æ–‡ä»¶è·¯å¾„",
    )

    # Pipeline control / æµæ°´çº¿æ§åˆ¶
    pipeline_group = parser.add_argument_group("Pipeline Control", "æµæ°´çº¿æ§åˆ¶")
    pipeline_group.add_argument(
        "--stage",
        choices=["nlr_localization", "protein_alignment", "augustus_training", 
                "gene_prediction", "evidence_integration", "all"],
        default="all",
        help="Pipeline stage to run / è¦è¿è¡Œçš„æµæ°´çº¿é˜¶æ®µ (default: all)",
    )
    pipeline_group.add_argument(
        "--resume-from",
        type=str,
        help="Resume pipeline from specific stage / ä»ç‰¹å®šé˜¶æ®µæ¢å¤æµæ°´çº¿",
    )
    pipeline_group.add_argument(
        "--skip-validation",
        action="store_true",
        help="Skip input file validation / è·³è¿‡è¾“å…¥æ–‡ä»¶éªŒè¯",
    )

    # Tool options / å·¥å…·é€‰é¡¹
    tool_group = parser.add_argument_group("Tool Options", "å·¥å…·é€‰é¡¹")
    tool_group.add_argument(
        "--augustus-model",
        type=str,
        default=None,
        help="Augustus species model / Augustusç‰©ç§æ¨¡å‹ (default: from config)",
    )
    tool_group.add_argument(
        "--threads", "-t",
        type=int,
        default=8,
        help="Number of threads to use / ä½¿ç”¨çš„çº¿ç¨‹æ•° (default: 8)",
    )
    tool_group.add_argument(
        "--memory",
        type=int,
        default=32,
        help="Maximum memory in GB / æœ€å¤§å†…å­˜GB (default: 32)",
    )
    
    # Augustus training options / Augustusè®­ç»ƒé€‰é¡¹
    training_group = parser.add_argument_group("Augustus Training", "Augustusè®­ç»ƒ")
    training_group.add_argument(
        "--enable-training",
        action="store_true",
        help="Enable Augustus model training with Miniprot results / å¯ç”¨åŸºäºMiniprotç»“æœçš„Augustusæ¨¡å‹è®­ç»ƒ",
    )
    training_group.add_argument(
        "--training-species-name",
        type=str,
        help="Name for the new trained Augustus species model / æ–°è®­ç»ƒçš„Augustusç‰©ç§æ¨¡å‹åç§°",
    )
    training_group.add_argument(
        "--training-quality",
        choices=["high", "medium", "low", "all"],
        default="high",
        help="Quality level of Miniprot results for training / ç”¨äºè®­ç»ƒçš„Miniprotç»“æœè´¨é‡çº§åˆ« (default: high)",
    )
    training_group.add_argument(
        "--training-min-genes",
        type=int,
        default=20,
        help="Minimum number of training genes required / æ‰€éœ€çš„æœ€å°‘è®­ç»ƒåŸºå› æ•° (default: 20)",
    )
    training_group.add_argument(
        "--training-optimization-rounds",
        type=int,
        default=1,
        help="Number of optimization rounds for training / è®­ç»ƒçš„ä¼˜åŒ–è½®æ•° (default: 1)",
    )
    training_group.add_argument(
        "--training-timeout",
        type=int,
        default=240,
        help="Training timeout in minutes / è®­ç»ƒè¶…æ—¶æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰ (default: 240)",
    )
    training_group.add_argument(
        "--skip-training-optimization",
        action="store_true",
        help="Skip parameter optimization during training (faster) / è·³è¿‡è®­ç»ƒæœŸé—´çš„å‚æ•°ä¼˜åŒ–ï¼ˆæ›´å¿«ï¼‰",
    )

    # Validation and debugging / éªŒè¯å’Œè°ƒè¯•
    debug_group = parser.add_argument_group("Validation & Debugging", "éªŒè¯å’Œè°ƒè¯•")
    debug_group.add_argument(
        "--validate-only",
        action="store_true",
        help="Only validate input files, don't run pipeline / ä»…éªŒè¯è¾“å…¥æ–‡ä»¶ï¼Œä¸è¿è¡Œæµæ°´çº¿",
    )
    debug_group.add_argument(
        "--check-tools",
        action="store_true",
        help="Check tool availability and exit / æ£€æŸ¥å·¥å…·å¯ç”¨æ€§å¹¶é€€å‡º",
    )
    debug_group.add_argument(
        "--verbose", "-v",
        action="count",
        default=0,
        help="Increase verbosity / å¢åŠ è¯¦ç»†ç¨‹åº¦ (use -vv for debug)",
    )
    debug_group.add_argument(
        "--log-file",
        type=Path,
        help="Path to log file / æ—¥å¿—æ–‡ä»¶è·¯å¾„",
    )
    debug_group.add_argument(
        "--dry-run",
        action="store_true",
        help="Show what would be done without executing / æ˜¾ç¤ºå°†è¦æ‰§è¡Œçš„æ“ä½œä½†ä¸å®é™…æ‰§è¡Œ",
    )

    return parser


def validate_arguments(args: argparse.Namespace) -> None:
    """
    Validate command line arguments
    éªŒè¯å‘½ä»¤è¡Œå‚æ•°
    
    Args:
        args: Parsed command line arguments
        
    Raises:
        SystemExit: If validation fails
    """
    errors = []

    # Check required inputs for pipeline execution
    if not args.check_tools and not args.validate_only:
        if args.stage in ["all", "nlr_localization", "protein_alignment"] and not args.genome:
            errors.append("Genome file (--genome) is required")

        if args.stage in ["all", "protein_alignment"] and not args.proteins:
            errors.append("Protein file (--proteins) is required")

    # Check file existence
    for file_arg, file_path in [
        ("--genome", args.genome),
        ("--proteins", args.proteins),
        ("--nlr-candidates", args.nlr_candidates),
        ("--config", args.config),
        ("--override-config", args.override_config),
    ]:
        if file_path and not file_path.exists():
            errors.append(f"File not found for {file_arg}: {file_path}")

    # Check output directory
    if args.output:
        try:
            args.output.mkdir(parents=True, exist_ok=True)
        except OSError as e:
            errors.append(f"Cannot create output directory {args.output}: {e}")

    # Check numeric arguments
    if args.threads <= 0:
        errors.append("Number of threads must be positive")

    if args.memory <= 0:
        errors.append("Memory limit must be positive")

    if errors:
        print("âŒ Argument validation failed:", file=sys.stderr)
        for error in errors:
            print(f"  - {error}", file=sys.stderr)
        sys.exit(1)


def setup_logging_from_args(args: argparse.Namespace) -> None:
    """
    Set up logging based on command line arguments
    æ ¹æ®å‘½ä»¤è¡Œå‚æ•°è®¾ç½®æ—¥å¿—
    
    Args:
        args: Parsed command line arguments
    """
    # Determine log level
    if args.verbose == 0:
        log_level = "INFO"
    elif args.verbose == 1:
        log_level = "DEBUG"
    else:
        log_level = "DEBUG"  # Very verbose

    # Set up logging
    setup_logging(
        level=log_level,
        log_file=args.log_file,
        console_output=True,
    )


def check_tool_availability(config_path: Path | None = None) -> bool:
    """
    Check availability of all required tools
    æ£€æŸ¥æ‰€æœ‰å¿…éœ€å·¥å…·çš„å¯ç”¨æ€§
    
    Args:
        config_path: Path to configuration file
        
    Returns:
        True if all tools are available, False otherwise
    """
    logger = get_logger(__name__)

    try:
        config = load_config(config_path)
        availability = config.validate_tool_availability()

        print("ğŸ”§ Tool Availability Check / å·¥å…·å¯ç”¨æ€§æ£€æŸ¥:")
        print("=" * 50)

        all_available = True
        for tool_name, is_available in availability.items():
            status = "âœ… Available" if is_available else "âŒ Not Found"
            print(f"{tool_name:20} {status}")
            if not is_available:
                all_available = False

        print("=" * 50)
        if all_available:
            print("âœ… All tools are available / æ‰€æœ‰å·¥å…·éƒ½å¯ç”¨")
        else:
            print("âŒ Some tools are missing / æŸäº›å·¥å…·ç¼ºå¤±")
            print("Please install missing tools or update configuration")

        return all_available

    except Exception as e:
        logger.error(f"Tool availability check failed: {e}")
        return False


def validate_input_files(args: argparse.Namespace) -> bool:
    """
    Validate input files
    éªŒè¯è¾“å…¥æ–‡ä»¶
    
    Args:
        args: Parsed command line arguments
        
    Returns:
        True if validation passes, False otherwise
    """
    logger = get_logger(__name__)

    try:
        validator = DataValidator(strict_mode=False)

        print("ğŸ“ Input File Validation / è¾“å…¥æ–‡ä»¶éªŒè¯:")
        print("=" * 50)

        validation_results = {}
        all_valid = True

        # Validate genome file
        if args.genome:
            print(f"Validating genome file: {args.genome}")
            result = validator.validate_genome_fasta(args.genome)
            validation_results["genome"] = result

            if result.is_valid:
                print(f"  âœ… Valid genome file ({result.record_count} sequences)")
            else:
                print(f"  âŒ Invalid genome file: {result.error_message}")
                all_valid = False

        # Validate protein file
        if args.proteins:
            print(f"Validating protein file: {args.proteins}")
            result = validator.validate_protein_fasta(args.proteins)
            validation_results["proteins"] = result

            if result.is_valid:
                print(f"  âœ… Valid protein file ({result.record_count} sequences)")
            else:
                print(f"  âŒ Invalid protein file: {result.error_message}")
                all_valid = False

        # Validate NLR candidates file
        if args.nlr_candidates:
            print(f"Validating NLR candidates file: {args.nlr_candidates}")
            result = validator.validate_gff(args.nlr_candidates)
            validation_results["nlr_candidates"] = result

            if result.is_valid:
                print(f"  âœ… Valid GFF file ({result.record_count} features)")
            else:
                print(f"  âŒ Invalid GFF file: {result.error_message}")
                all_valid = False

        print("=" * 50)
        if all_valid:
            print("âœ… All input files are valid / æ‰€æœ‰è¾“å…¥æ–‡ä»¶éƒ½æœ‰æ•ˆ")
        else:
            print("âŒ Some input files are invalid / æŸäº›è¾“å…¥æ–‡ä»¶æ— æ•ˆ")

        # Save validation report
        if validation_results:
            report_path = args.output / "input_validation_report.md"
            report = validator.generate_validation_report(validation_results, report_path)
            print(f"ğŸ“„ Validation report saved to: {report_path}")

        return all_valid

    except Exception as e:
        logger.error(f"Input validation failed: {e}")
        return False


def run_pipeline(args: argparse.Namespace) -> bool:
    """
    Run the NBS annotation pipeline
    è¿è¡ŒNBSæ³¨é‡Šæµæ°´çº¿
    
    Args:
        args: Parsed command line arguments
        
    Returns:
        True if pipeline succeeds, False otherwise
    """
    logger = get_logger(__name__)

    try:
        # Load configuration
        env_overrides = {
            "pipeline.parallel.max_workers": args.threads,
            "pipeline.memory.max_memory_gb": args.memory,
        }
        
        # Add Augustus training overrides if enabled
        if args.enable_training:
            env_overrides.update({
                "tools.augustus.training.miniprot_training.enabled": True,
                "tools.augustus.training.miniprot_training.quality_filter": args.training_quality,
                "tools.augustus.training.miniprot_training.min_training_genes": args.training_min_genes,
                "tools.augustus.training.miniprot_training.optimization_rounds": 0 if args.skip_training_optimization else args.training_optimization_rounds,
                "tools.augustus.training.miniprot_training.timeout_minutes": args.training_timeout,
            })
            
            if args.training_species_name:
                env_overrides["tools.augustus.training.miniprot_training.species_name"] = args.training_species_name
        
        config = load_config_with_overrides(
            base_config_path=args.config,
            override_config_path=args.override_config,
            env_overrides=env_overrides,
        )

        # Initialize pipeline with absolute output path
        pipeline = NBSAnnotationPipeline(
            config=config,
            output_base_dir=args.output.resolve(),
            pipeline_id=args.pipeline_id,
        )

        print(f"ğŸš€ Starting NBS annotation pipeline: {pipeline.pipeline_id}")
        print(f"ğŸ“‚ Output directory: {pipeline.pipeline_output_dir}")

        if args.dry_run:
            print("ğŸ” Dry run mode - showing planned execution:")
            print(f"  - Genome file: {args.genome}")
            print(f"  - Protein file: {args.proteins}")
            print(f"  - Pipeline stage: {args.stage}")
            print(f"  - Augustus model: {args.augustus_model}")
            print(f"  - Augustus training enabled: {args.enable_training}")
            if args.enable_training:
                print(f"  - Training species name: {args.training_species_name}")
                print(f"  - Training quality: {args.training_quality}")
                print(f"  - Training min genes: {args.training_min_genes}")
                print(f"  - Training optimization rounds: {args.training_optimization_rounds}")
                print(f"  - Training timeout: {args.training_timeout} minutes")
            print(f"  - Threads: {args.threads}")
            print(f"  - Memory: {args.memory}GB")
            return True

        # Run pipeline based on stage
        start_time = time.time()

        if args.stage == "all":
            # Run full pipeline
            results = pipeline.run_full_pipeline(
                genome_path=args.genome,
                protein_path=args.proteins,
                augustus_model=args.augustus_model,
                training_species_name=args.training_species_name,
            )
        # Run specific stage
        elif args.stage == "nlr_localization":
            results = pipeline.run_nlr_localization(genome_path=args.genome)
        elif args.stage == "protein_alignment":
            results = pipeline.run_protein_alignment(
                genome_path=args.genome,
                protein_path=args.proteins,
            )
        elif args.stage == "augustus_training":
            # Run Augustus training as standalone stage
            results = pipeline.run_augustus_training(
                training_species_name=args.training_species_name,
            )
        elif args.stage == "gene_prediction":
            if not args.nlr_candidates:
                raise NBSAnnotationError("NLR candidates file required for gene prediction stage")
            results = pipeline.run_gene_prediction(
                nlr_candidates_path=args.nlr_candidates,
                training_model=args.augustus_model,
            )
        elif args.stage == "evidence_integration":
            # For evidence integration, we need existing prediction files
            prediction_files = []
            
            # Look for Augustus predictions
            augustus_file = args.output / "gene_prediction" / "predictions_genome_coords.gff"
            if not augustus_file.exists():
                augustus_file = args.output / "gene_prediction" / "predictions.gff"
            if augustus_file.exists():
                prediction_files.append(augustus_file)
            
            # Look for Miniprot alignments
            miniprot_file = args.output / "protein_alignment" / "alignments.gff"
            if miniprot_file.exists():
                prediction_files.append(miniprot_file)
            
            # Look for NLR candidates
            nlr_file = args.nlr_candidates or (args.output / "nlr_localization" / "NLR_candidates.gff")
            
            if not prediction_files:
                raise NBSAnnotationError("No prediction files found for evidence integration. Run previous stages first.")
            
            results = pipeline.run_evidence_integration(
                prediction_files=prediction_files,
                genome_file=args.genome,
                nlr_candidates_file=nlr_file if nlr_file and nlr_file.exists() else None,
            )
        else:
            raise NBSAnnotationError(f"Stage not implemented: {args.stage}")

        execution_time = time.time() - start_time

        # Report results
        print("=" * 50)
        print("âœ… Pipeline completed successfully!")
        print(f"â±ï¸  Execution time: {execution_time:.1f} seconds")

        if hasattr(results, "stages_completed"):
            print(f"ğŸ“Š Stages completed: {', '.join(results.stages_completed)}")

        if hasattr(results, "output_files"):
            print("ğŸ“ Output files:")
            for file_type, file_path in results.output_files.items():
                print(f"  - {file_type}: {file_path}")

        return True

    except NBSAnnotationError as e:
        logger.error(f"Pipeline error: {e}")
        print(f"âŒ Pipeline failed: {e}", file=sys.stderr)
        return False
    except Exception as e:
        logger.error(f"Unexpected error: {e}")
        print(f"âŒ Unexpected error: {e}", file=sys.stderr)
        return False


def main() -> int:
    """
    Main entry point
    ä¸»è¦å…¥å£ç‚¹
    
    Returns:
        Exit code (0 for success, 1 for failure)
    """
    # Parse command line arguments
    parser = setup_argument_parser()
    args = parser.parse_args()

    # Set up logging early
    setup_logging_from_args(args)
    logger = get_logger(__name__)

    try:
        # Validate arguments
        validate_arguments(args)

        # Handle special modes
        if args.check_tools:
            success = check_tool_availability(args.config)
            return 0 if success else 1

        if args.validate_only:
            success = validate_input_files(args)
            return 0 if success else 1

        # Validate inputs unless skipped
        if not args.skip_validation:
            validation_success = validate_input_files(args)
            if not validation_success:
                print("âŒ Input validation failed. Use --skip-validation to bypass.")
                return 1

        # Run pipeline
        success = run_pipeline(args)
        return 0 if success else 1

    except KeyboardInterrupt:
        print("\nâš ï¸  Pipeline interrupted by user", file=sys.stderr)
        logger.info("Pipeline interrupted by user")
        return 1
    except Exception as e:
        print(f"âŒ Fatal error: {e}", file=sys.stderr)
        logger.error(f"Fatal error: {e}")
        return 1


if __name__ == "__main__":
    sys.exit(main())
